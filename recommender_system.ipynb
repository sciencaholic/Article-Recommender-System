{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings that might clutter the output, ensuring that the results are clean and readable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ensure compatibility with Python 2 for division, print function, and unicode literals, making the code more forward-compatible with Python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from math import log\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Articles: 293119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12579008</td>\n",
       "      <td>You have two days to comment if you want stem ...</td>\n",
       "      <td>http://www.regulations.gov/document?D=FDA-2015...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>altstar</td>\n",
       "      <td>9/26/2016 3:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12579005</td>\n",
       "      <td>SQLAR  the SQLite Archiver</td>\n",
       "      <td>https://www.sqlite.org/sqlar/doc/trunk/README.md</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>blacksqr</td>\n",
       "      <td>9/26/2016 3:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12578997</td>\n",
       "      <td>What if we just printed a flatscreen televisio...</td>\n",
       "      <td>https://medium.com/vanmoof/our-secrets-out-f21...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pavel_lishin</td>\n",
       "      <td>9/26/2016 3:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12578989</td>\n",
       "      <td>algorithmic music</td>\n",
       "      <td>http://cacm.acm.org/magazines/2011/7/109891-al...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>poindontcare</td>\n",
       "      <td>9/26/2016 3:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12578979</td>\n",
       "      <td>How the Data Vault Enables the Next-Gen Data W...</td>\n",
       "      <td>https://www.talend.com/blog/2016/05/12/talend-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>markgainor1</td>\n",
       "      <td>9/26/2016 3:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  12579008  You have two days to comment if you want stem ...   \n",
       "1  12579005                         SQLAR  the SQLite Archiver   \n",
       "2  12578997  What if we just printed a flatscreen televisio...   \n",
       "3  12578989                                  algorithmic music   \n",
       "4  12578979  How the Data Vault Enables the Next-Gen Data W...   \n",
       "\n",
       "                                                 url  num_points  \\\n",
       "0  http://www.regulations.gov/document?D=FDA-2015...           1   \n",
       "1   https://www.sqlite.org/sqlar/doc/trunk/README.md           1   \n",
       "2  https://medium.com/vanmoof/our-secrets-out-f21...           1   \n",
       "3  http://cacm.acm.org/magazines/2011/7/109891-al...           1   \n",
       "4  https://www.talend.com/blog/2016/05/12/talend-...           1   \n",
       "\n",
       "   num_comments        author      created_at  \n",
       "0             0       altstar  9/26/2016 3:26  \n",
       "1             0      blacksqr  9/26/2016 3:24  \n",
       "2             0  pavel_lishin  9/26/2016 3:19  \n",
       "3             0  poindontcare  9/26/2016 3:16  \n",
       "4             0   markgainor1  9/26/2016 3:14  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data \n",
    "path = \"https://drive.google.com/uc?id=11FNXuP673a1Bt77a-G9SlPEx_njqr8Ex\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(f\"Total Articles: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [two, days, comment, want, stem, cells, classi...\n",
      "1                             [sqlar, sqlite, archiver]\n",
      "2        [printed, flatscreen, television, side, boxes]\n",
      "3                                  [algorithmic, music]\n",
      "4     [data, vault, enables, nextgen, data, warehous...\n",
      "5                            [saving, hassle, shopping]\n",
      "6     [macalifa, new, opensource, music, app, uwp, w...\n",
      "7     [github, theweavrsmacalifa, music, player, wri...\n",
      "8                     [google, allo, first, impression]\n",
      "9          [advanced, multimedia, linux, command, line]\n",
      "10              [ask, hn, tld, use, local, development]\n",
      "11                                        [muroc, maru]\n",
      "12                   [companies, make, products, worse]\n",
      "13                           [tuning, aws, sqs, queues]\n",
      "14                                    [promise, github]\n",
      "15                              [joint, rd, ups, downs]\n",
      "16    [ibm, announces, next, implementation, apples,...\n",
      "17       [amazons, algorithms, dont, find, best, deals]\n",
      "18                                  [ruffled, feathers]\n",
      "19              [veil, ignorance, design, accessbility]\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocess titles from HN posts\n",
    "\n",
    "# The preprocessing steps involve converting titles to lowercase, removing punctuation, and splitting the titles into tokens (words).\n",
    "from string import punctuation\n",
    "punctrans = str.maketrans(dict.fromkeys(punctuation)) \n",
    "\n",
    "def tokenize(title):\n",
    "    x = title.lower() # Lowercase\n",
    "    x = x.encode('ascii', 'ignore').decode() # Keep only ascii chars.\n",
    "    x = x.translate(punctrans) # Remove punctuation\n",
    "    return x.split() # Return tokenized.\n",
    "\n",
    "texts_tokenized = hn['title'].apply(tokenize)\n",
    "\n",
    "# Stopwords (common words like \"the\", \"is\", etc.) are removed from the tokenized texts to reduce noise in the data.\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(0, 5):\n",
    "    for text in texts_tokenized:\n",
    "        for x in text:\n",
    "            if x in sw:\n",
    "                text.remove(x)\n",
    "\n",
    "print(texts_tokenized[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99044\n",
      "\n",
      "Most common:  [('hn', 20237), ('show', 10753), ('new', 10080), ('ask', 9582), ('data', 6628), ('google', 5532), ('app', 5124), ('using', 4613), ('us', 4189), ('web', 4134), ('startup', 3849), ('open', 3828), ('first', 3730), ('code', 3705), ('apple', 3695), ('pdf', 3659), ('software', 3558), ('video', 3462), ('tech', 3410), ('free', 3180)]\n",
      "\n",
      "Least common:  [('codenewbie', 1), ('makefileinspired', 1), ('managerbootstrapper', 1), ('reduxrouting', 1), ('libraryagnostic', 1), ('mocktheclock', 1), ('uncompromising', 1), ('appypaper', 1), ('ringcx', 1), ('getawesomeness', 1), ('keck', 1), ('developerfounderceo', 1), ('integeration', 1), ('gayford', 1), ('superweed', 1), ('prewwii', 1), ('microserivces', 1), ('interdependency', 1), ('tempted', 1), ('isare', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Compute unigram and bigram counts\n",
    "\n",
    "# Unigrams (single words) and bigrams (pairs of words) are counted for calculating word frequencies and co-occurrences necessary for computing PMI scores later.\n",
    "from collections import Counter\n",
    "cx = Counter()\n",
    "cxy = Counter()\n",
    "\n",
    "for text in texts_tokenized:\n",
    "    for x in text:\n",
    "        cx[x] += 1\n",
    "    \n",
    "    for x, y in set(map(tuple, map(sorted, combinations(text, 2)))):\n",
    "        cxy[(x,y)] += 1\n",
    "        \n",
    "print(len(cx))\n",
    "print('\\nMost common: ', cx.most_common()[:20])\n",
    "print('\\nLeast common: ', cx.most_common()[(len(cx)-20):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99044 tokens before\n",
      "2022 tokens after\n",
      "\n",
      "Most common: [('hn', 20237), ('show', 10753), ('new', 10080), ('ask', 9582), ('data', 6628), ('google', 5532), ('app', 5124), ('using', 4613), ('us', 4189), ('web', 4134), ('startup', 3849), ('open', 3828), ('first', 3730), ('code', 3705), ('apple', 3695), ('pdf', 3659), ('software', 3558), ('video', 3462), ('tech', 3410), ('free', 3180)]\n",
      "\n",
      "Least common: [('views', 148), ('emulator', 148), ('directory', 148), ('director', 148), ('amiga', 148), ('bigger', 147), ('hold', 147), ('depression', 147), ('philosophy', 147), ('parts', 147), ('infographic', 147), ('average', 147), ('scam', 147), ('generating', 147), ('targets', 147), ('volkswagen', 147), ('investor', 147), ('classes', 147), ('match', 147), ('timeline', 147)]\n"
     ]
    }
   ],
   "source": [
    "# Remove infrequent unigrams.\n",
    "\n",
    "# Terms that appear less frequently than a certain threshold are removed from consideration to help reduce the dimensionality of the data and focus the analysis on more significant terms.\n",
    "print('%d tokens before' % len(cx))\n",
    "\n",
    "min_count = (1 / 2000) * len(df) # = 146.5595\n",
    "\n",
    "for x in list(cx.keys()):\n",
    "    if cx[x] < min_count:\n",
    "        del cx[x]\n",
    "\n",
    "# Remove infrequent bigrams.\n",
    "\n",
    "for x, y in list(cxy.keys()):\n",
    "    if x not in cx or y not in cx:\n",
    "        del cxy[(x, y)]\n",
    "\n",
    "print('%d tokens after' % len(cx))\n",
    "print('\\nMost common:', cx.most_common()[:20])\n",
    "print('\\nLeast common:', cx.most_common()[(len(cx)-20):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build unigram <-> index lookup.\n",
    "\n",
    "# Lookup tables (x2i and i2x) are created to map words to indices and vice versa. This is useful for matrix operations where words need to be represented as numerical indices.\n",
    "x2i, i2x = {}, {}\n",
    "for i, x in enumerate(cx.keys()):\n",
    "    x2i[x] = i\n",
    "    i2x[i] = x\n",
    "    \n",
    "# Sum unigram and bigram counts for computing probabilities.\n",
    "# i.e. p(x) = count(x) / sum(all counts).\n",
    "\n",
    "sx = sum(cx.values())\n",
    "sxy = sum(cxy.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Mutual Information (PMI)\n",
    "\n",
    "Pointwise Mutual Information (PMI) is a statistical measure to calculate the association between two words in a given corpus. PMI is calculated by comparing the probability of the co-occurrence of two words with their individual probabilities of occurrence.\n",
    "\n",
    "The formula for PMI is as follows:\n",
    "\n",
    "$$\n",
    "\\text{PMI}(x,y) = \\log\\left(\\frac{P(x,y)}{P(x)P(y)}\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- \\(x\\) and \\(y\\) are two words being considered,\n",
    "- \\(P(x)\\) is the probability of the occurrence of word \\(x\\) in the corpus,\n",
    "- \\(P(y)\\) is the probability of the occurrence of word \\(y\\) in the corpus, and\n",
    "- \\(P(x,y)\\) is the probability of the co-occurrence of words \\(x\\) and \\(y\\) in the corpus.\n",
    "\n",
    "For terms with three words, the formula becomes:\n",
    "\n",
    "$$\n",
    "\\text{PMI}(z, y, x) = \\log\\left(\\frac{P(z,y,x)}{P(z)P(y)P(x)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\log\\left(\\frac{P(z|y, x)P(y|x)P(x)}{P(z)P(y)P(x)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\log\\left(\\frac{P(z|y, x)P(y|x)}{P(z)P(y)}\\right)\n",
    "$$\n",
    "\n",
    "PMI values can range from \\(-\\infty\\) to \\(\\infty\\). Positive PMI values indicate that the words have a strong association, while negative values indicate that the words are unlikely to appear together.\n",
    "\n",
    "## Example\n",
    "\n",
    "Consider a small corpus of text:\n",
    "\n",
    "> \"The cat sat on the mat. The dog sat on the mat.\"\n",
    "\n",
    "Let’s calculate the PMI of the words \"cat\" and \"mat\":\n",
    "\n",
    "- P(cat) = 1/6    \n",
    "- P(mat) = 2/6 = 1/3    \n",
    "- P(cat, mat) = 1/6    \n",
    "\n",
    "$$\n",
    "\\text{PMI}(\\text{cat, mat}) = \\log\\left(\\frac{\\frac{1}{6}}{\\frac{1}{6} \\cdot \\frac{1}{3}}\\right) = \\log(3) \\approx 1.0986\n",
    "$$\n",
    "\n",
    "The positive PMI value suggests that \"cat\" and \"mat\" have a strong association and are likely to appear together.\n",
    "\n",
    "## Real-time Application Considerations\n",
    "\n",
    "In real-time problems, calculating PMI for longer terms (length > 2) is still very costly for any relatively large corpus of text. We can either go for calculating it only for a two-word term or choose to skip it if we know that there are only a few occurrences of such terms.\n",
    "\n",
    "PMI is commonly used in various NLP tasks such as information retrieval, topic modeling, and sentiment analysis, to identify and analyze the relationships between words in a corpus.\n",
    "\n",
    "\n",
    "Reference- [Pointwise Mutual Information in NLP](https://wisdomml.in/concept-of-pointwise-mutual-information-in-nlp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559498 non-zero elements\n",
      "\n",
      "Sample PMI values\n",
      " [(('cheat', 'sheet'), 7.741703919492517),\n",
      " (('gravitational', 'waves'), 7.594274561632172),\n",
      " (('peter', 'thiel'), 7.501114832399731),\n",
      " (('oculus', 'rift'), 7.444931552717988),\n",
      " (('nobel', 'prize'), 7.430011693174276),\n",
      " (('cook', 'tim'), 7.387140034347794),\n",
      " (('virus', 'zika'), 7.218029192769757),\n",
      " (('edward', 'snowden'), 7.154950416854075),\n",
      " (('clinton', 'hillary'), 7.109859339780078),\n",
      " (('area', 'bay'), 7.103617893940743),\n",
      " (('boot', 'spring'), 7.096688700497847),\n",
      " (('states', 'united'), 7.069464109429888),\n",
      " (('korea', 'north'), 7.054418293068599),\n",
      " (('panama', 'papers'), 7.0542136375644935),\n",
      " (('elon', 'musk'), 6.952284458229978)]\n"
     ]
    }
   ],
   "source": [
    "# Accumulate data, rows, and cols to build sparse PMI matrix\n",
    "\n",
    "# The probabilities of each unigram and bigram are calculated based on their frequencies. These probabilities are used to compute the PMI scores for each word pair, which are then stored in a sparse matrix format to optimize memory usage.\n",
    "from scipy.sparse import csc_matrix\n",
    "from pprint import pformat\n",
    "\n",
    "pmi_samples = Counter()\n",
    "data, rows, cols = [], [], []\n",
    "\n",
    "for (x, y), n in cxy.items():\n",
    "    rows.append(x2i[x])\n",
    "    cols.append(x2i[y])\n",
    "    data.append(log((n / sxy) / (cx[x] / sx) / (cx[y] / sx)))\n",
    "    pmi_samples[(x, y)] = data[-1]\n",
    "\n",
    "# A sparse matrix is constructed using the computed PMI values. This matrix represents the pointwise mutual information between all pairs of words in the dataset.\n",
    "PMI = csc_matrix((data, (rows, cols)))\n",
    "\n",
    "print('%d non-zero elements' % PMI.count_nonzero())\n",
    "print('\\nSample PMI values\\n', pformat(pmi_samples.most_common()[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)\n",
    "\n",
    "Singular Value Decomposition is a way to factor a matrix \\( A \\) into three matrices, as follows:\n",
    "\n",
    "$$ A = U \\cdot S \\cdot V^T $$\n",
    "\n",
    "Where \\( U \\) and \\( V \\) are orthogonal matrices, and \\( S \\) is a diagonal matrix containing the singular values of \\( A \\).\n",
    "\n",
    "## Note:\n",
    "\n",
    "- The matrix is considered an **orthogonal matrix** if the product of a matrix and its transpose gives an identity value.\n",
    "- A matrix is **diagonal** if it has non-zero elements only in the diagonal, running from the upper left to the lower right corner of the matrix.\n",
    "\n",
    "Here, \\( U \\) and \\( V \\) represent the left and right singular vectors of \\( A \\), respectively, and \\( S \\) represents the singular values of \\( A \\).\n",
    "\n",
    "## Algorithm for Computing SVD\n",
    "\n",
    "The algorithm for computing the SVD of matrix \\( A \\) can be summarized in the following steps:\n",
    "\n",
    "1. Compute the eigendecomposition of the symmetric matrix \\( A^T A \\). This can be done using any standard eigendecomposition algorithm.\n",
    "2. Compute the singular values of \\( A \\) as the square root of the eigenvalues of \\( A^T A \\). Sort the singular values in descending order.\n",
    "3. Compute the left and right singular vectors of \\( A \\) as follows:\n",
    "   - For each singular value, find the corresponding eigenvector of \\( A^T A \\).\n",
    "   - Normalize each eigenvector to have a unit length.\n",
    "   - The left singular vectors of \\( A \\) are the eigenvectors of \\( AA^T \\) corresponding to the nonzero singular values of \\( A \\).\n",
    "   - The right singular vectors of \\( A \\) are the normalized eigenvectors of \\( A^T A \\).\n",
    "\n",
    "4. Assemble the SVD of \\( A \\) as follows:\n",
    "   - The diagonal entries of \\( S \\) are the singular values of \\( A \\), sorted in descending order.\n",
    "   - The columns of \\( U \\) are the corresponding left singular vectors of \\( A \\).\n",
    "   - The columns of \\( V \\) are the corresponding right singular vectors of \\( A \\).\n",
    "\n",
    "## Application in PMI Matrix Factorization and Recommender Systems\n",
    "\n",
    "The PMI matrix is factorized using Singular Value Decomposition (SVD), which decomposes the matrix into three smaller matrices. This step reduces the dimensionality of the data and uncovers latent semantic structures within it.\n",
    "\n",
    "SVD is applied to the PMI matrix, specifying the number of dimensions (k) to reduce to. The resulting matrix \\( U \\) contains vectors representing each word in a reduced-dimensional space.\n",
    "\n",
    "SVD breaks down a large, complex matrix (which could represent, for example, user ratings for different movies) into simpler, smaller pieces that capture the most important underlying patterns. This can reveal hidden relationships between items in the dataset, like uncovering latent genres in movies that aren't explicitly labeled but are reflected in user ratings (e.g., a \"dark comedy\" genre that's not officially recognized but consistently liked by a certain group of users).\n",
    "\n",
    "### Benefits of Using SVD in Recommender Systems\n",
    "\n",
    "1. **Dimensionality Reduction**: It simplifies the data by reducing the number of variables under consideration, focusing only on those that contribute most significantly to the variation in the dataset. This makes the system more efficient and less prone to overfitting.\n",
    "2. **Feature Extraction**: It identifies latent features that represent underlying patterns in the data, such as hidden movie genres or unspoken user preferences. These features can then be used to make more accurate recommendations by matching items and users based on these deeper, hidden characteristics.\n",
    "\n",
    "By applying PMI, we can find strong word associations to understand content relationships better, and with SVD, we can uncover and utilize latent features in the data to make our recommender system more insightful and effective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize the PMI matrix using sparse SVD\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "U, S, V = svds(PMI, k=20) \n",
    "norms = np.sqrt(np.sum(np.square(U), axis=1, keepdims=True))\n",
    "U /= np.maximum(norms, 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter search word: javascript\n",
      "library\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243976</th>\n",
       "      <td>10532957</td>\n",
       "      <td>TensorFlow: open-source library for machine in...</td>\n",
       "      <td>http://tensorflow.org/</td>\n",
       "      <td>1559</td>\n",
       "      <td>196</td>\n",
       "      <td>jmomarty</td>\n",
       "      <td>11/9/2015 13:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95612</th>\n",
       "      <td>11735393</td>\n",
       "      <td>Libui: GUI library in C</td>\n",
       "      <td>https://github.com/andlabs/libui</td>\n",
       "      <td>373</td>\n",
       "      <td>182</td>\n",
       "      <td>avitex</td>\n",
       "      <td>5/20/2016 3:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175124</th>\n",
       "      <td>11076390</td>\n",
       "      <td>Bokeh  a Python interactive visualization library</td>\n",
       "      <td>http://bokeh.pydata.org/en/latest/</td>\n",
       "      <td>295</td>\n",
       "      <td>66</td>\n",
       "      <td>sonabinu</td>\n",
       "      <td>2/10/2016 21:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58224</th>\n",
       "      <td>12064022</td>\n",
       "      <td>Rustls: new, modern TLS library written in Rust</td>\n",
       "      <td>https://github.com/ctz/rustls</td>\n",
       "      <td>287</td>\n",
       "      <td>108</td>\n",
       "      <td>adamnemecek</td>\n",
       "      <td>7/10/2016 0:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178110</th>\n",
       "      <td>11053525</td>\n",
       "      <td>Records: Python library for making raw SQL que...</td>\n",
       "      <td>https://github.com/kennethreitz/records</td>\n",
       "      <td>257</td>\n",
       "      <td>129</td>\n",
       "      <td>infinite8s</td>\n",
       "      <td>2/7/2016 16:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "243976  10532957  TensorFlow: open-source library for machine in...   \n",
       "95612   11735393                            Libui: GUI library in C   \n",
       "175124  11076390  Bokeh  a Python interactive visualization library   \n",
       "58224   12064022    Rustls: new, modern TLS library written in Rust   \n",
       "178110  11053525  Records: Python library for making raw SQL que...   \n",
       "\n",
       "                                            url  num_points  num_comments  \\\n",
       "243976                   http://tensorflow.org/        1559           196   \n",
       "95612          https://github.com/andlabs/libui         373           182   \n",
       "175124       http://bokeh.pydata.org/en/latest/         295            66   \n",
       "58224             https://github.com/ctz/rustls         287           108   \n",
       "178110  https://github.com/kennethreitz/records         257           129   \n",
       "\n",
       "             author       created_at  \n",
       "243976     jmomarty  11/9/2015 13:50  \n",
       "95612        avitex   5/20/2016 3:29  \n",
       "175124     sonabinu  2/10/2016 21:56  \n",
       "58224   adamnemecek   7/10/2016 0:35  \n",
       "178110   infinite8s   2/7/2016 16:53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42450</th>\n",
       "      <td>12201387</td>\n",
       "      <td>Pitfalls of fat arrow functions of es6</td>\n",
       "      <td>http://quanz.in/why-dont-i-like-fat-arrow-from...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>rupoJS</td>\n",
       "      <td>8/1/2016 10:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40400</th>\n",
       "      <td>12218304</td>\n",
       "      <td>Free Modern JavaScript Course (webpack, nodejs...</td>\n",
       "      <td>http://courses.angularclass.com/courses/modern...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>gdi2290</td>\n",
       "      <td>8/3/2016 14:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115106</th>\n",
       "      <td>11568631</td>\n",
       "      <td>Show HN: RunJS-SlackBot-A Slack bot that runs ...</td>\n",
       "      <td>https://github.com/prashantagarwal/RunJS-Slackbot</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>titanprashant</td>\n",
       "      <td>4/26/2016 0:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162891</th>\n",
       "      <td>11172862</td>\n",
       "      <td>Best practice of building chrome extension usi...</td>\n",
       "      <td>https://github.com/ProjecToday/es6-chrome-exte...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>timqian</td>\n",
       "      <td>2/25/2016 7:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236116</th>\n",
       "      <td>10591583</td>\n",
       "      <td>Jump.js  a 0 dependency smooth scrolling es6 l...</td>\n",
       "      <td>https://github.com/callmecavs/jump.js</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>jaxgeller</td>\n",
       "      <td>11/18/2015 23:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "42450   12201387             Pitfalls of fat arrow functions of es6   \n",
       "40400   12218304  Free Modern JavaScript Course (webpack, nodejs...   \n",
       "115106  11568631  Show HN: RunJS-SlackBot-A Slack bot that runs ...   \n",
       "162891  11172862  Best practice of building chrome extension usi...   \n",
       "236116  10591583  Jump.js  a 0 dependency smooth scrolling es6 l...   \n",
       "\n",
       "                                                      url  num_points  \\\n",
       "42450   http://quanz.in/why-dont-i-like-fat-arrow-from...           7   \n",
       "40400   http://courses.angularclass.com/courses/modern...           4   \n",
       "115106  https://github.com/prashantagarwal/RunJS-Slackbot           2   \n",
       "162891  https://github.com/ProjecToday/es6-chrome-exte...           2   \n",
       "236116              https://github.com/callmecavs/jump.js           2   \n",
       "\n",
       "        num_comments         author        created_at  \n",
       "42450              0         rupoJS    8/1/2016 10:48  \n",
       "40400              1        gdi2290    8/3/2016 14:51  \n",
       "115106             0  titanprashant    4/26/2016 0:52  \n",
       "162891             0        timqian    2/25/2016 7:14  \n",
       "236116             1      jaxgeller  11/18/2015 23:42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "js\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>10882563</td>\n",
       "      <td>TrendMicro Node.js HTTP server listening on lo...</td>\n",
       "      <td>https://code.google.com/p/google-security-rese...</td>\n",
       "      <td>1030</td>\n",
       "      <td>229</td>\n",
       "      <td>tptacek</td>\n",
       "      <td>1/11/2016 19:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114390</th>\n",
       "      <td>11574705</td>\n",
       "      <td>Node.js v6.0 Released</td>\n",
       "      <td>https://nodejs.org/en/blog/announcements/v6-re...</td>\n",
       "      <td>728</td>\n",
       "      <td>159</td>\n",
       "      <td>JoshGlazebrook</td>\n",
       "      <td>4/26/2016 19:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158811</th>\n",
       "      <td>11204481</td>\n",
       "      <td>Free React.js Fundamentals Course</td>\n",
       "      <td>http://courses.reactjsprogram.com/courses/reac...</td>\n",
       "      <td>676</td>\n",
       "      <td>112</td>\n",
       "      <td>tm33</td>\n",
       "      <td>3/1/2016 17:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26393</th>\n",
       "      <td>12338365</td>\n",
       "      <td>Node.js is one of the worst things to happen t...</td>\n",
       "      <td>http://harmful.cat-v.org/software/node.js</td>\n",
       "      <td>624</td>\n",
       "      <td>552</td>\n",
       "      <td>behnamoh</td>\n",
       "      <td>8/22/2016 18:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165432</th>\n",
       "      <td>11153757</td>\n",
       "      <td>Draft.js  Rich Text Editor Framework for React</td>\n",
       "      <td>http://facebook.github.io/draft-js/</td>\n",
       "      <td>592</td>\n",
       "      <td>112</td>\n",
       "      <td>tilt</td>\n",
       "      <td>2/22/2016 19:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "199984  10882563  TrendMicro Node.js HTTP server listening on lo...   \n",
       "114390  11574705                              Node.js v6.0 Released   \n",
       "158811  11204481                  Free React.js Fundamentals Course   \n",
       "26393   12338365  Node.js is one of the worst things to happen t...   \n",
       "165432  11153757     Draft.js  Rich Text Editor Framework for React   \n",
       "\n",
       "                                                      url  num_points  \\\n",
       "199984  https://code.google.com/p/google-security-rese...        1030   \n",
       "114390  https://nodejs.org/en/blog/announcements/v6-re...         728   \n",
       "158811  http://courses.reactjsprogram.com/courses/reac...         676   \n",
       "26393           http://harmful.cat-v.org/software/node.js         624   \n",
       "165432                http://facebook.github.io/draft-js/         592   \n",
       "\n",
       "        num_comments          author       created_at  \n",
       "199984           229         tptacek  1/11/2016 19:22  \n",
       "114390           159  JoshGlazebrook  4/26/2016 19:14  \n",
       "158811           112            tm33   3/1/2016 17:47  \n",
       "26393            552        behnamoh  8/22/2016 18:33  \n",
       "165432           112            tilt  2/22/2016 19:57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223060</th>\n",
       "      <td>10692247</td>\n",
       "      <td>java.nio.file.WatchService is subtly broken on...</td>\n",
       "      <td>http://blog.omega-prime.co.uk/?p=161</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>lelf</td>\n",
       "      <td>12/7/2015 20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30424</th>\n",
       "      <td>12302609</td>\n",
       "      <td>Surfingkeys  Expand your browser with javascri...</td>\n",
       "      <td>https://github.com/brookhong/Surfingkeys</td>\n",
       "      <td>77</td>\n",
       "      <td>26</td>\n",
       "      <td>ldong</td>\n",
       "      <td>8/17/2016 4:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112674</th>\n",
       "      <td>11588927</td>\n",
       "      <td>Deprecating: java.util.Optional.get()?</td>\n",
       "      <td>http://royvanrijn.com/blog/2016/04/deprecating...</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>redcodenl</td>\n",
       "      <td>4/28/2016 14:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224003</th>\n",
       "      <td>10685137</td>\n",
       "      <td>Show HN: Kipplr  The most absurd application i...</td>\n",
       "      <td>http://www.kipplr.xyz</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>gioscarab</td>\n",
       "      <td>12/6/2015 12:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149824</th>\n",
       "      <td>11276940</td>\n",
       "      <td>Show HN: Rogue AI Dungeon, javacript bot scrip...</td>\n",
       "      <td>http://bovard.github.io/raid/</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>cdubzzz</td>\n",
       "      <td>3/13/2016 9:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "223060  10692247  java.nio.file.WatchService is subtly broken on...   \n",
       "30424   12302609  Surfingkeys  Expand your browser with javascri...   \n",
       "112674  11588927             Deprecating: java.util.Optional.get()?   \n",
       "224003  10685137  Show HN: Kipplr  The most absurd application i...   \n",
       "149824  11276940  Show HN: Rogue AI Dungeon, javacript bot scrip...   \n",
       "\n",
       "                                                      url  num_points  \\\n",
       "223060               http://blog.omega-prime.co.uk/?p=161          85   \n",
       "30424            https://github.com/brookhong/Surfingkeys          77   \n",
       "112674  http://royvanrijn.com/blog/2016/04/deprecating...          53   \n",
       "224003                              http://www.kipplr.xyz          18   \n",
       "149824                      http://bovard.github.io/raid/          17   \n",
       "\n",
       "        num_comments     author       created_at  \n",
       "223060             6       lelf  12/7/2015 20:03  \n",
       "30424             26      ldong   8/17/2016 4:55  \n",
       "112674            90  redcodenl  4/28/2016 14:05  \n",
       "224003             2  gioscarab  12/6/2015 12:49  \n",
       "149824             4    cdubzzz   3/13/2016 9:16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123721</th>\n",
       "      <td>11497826</td>\n",
       "      <td>Hjson, the Human JSON</td>\n",
       "      <td>http://hjson.org/</td>\n",
       "      <td>257</td>\n",
       "      <td>214</td>\n",
       "      <td>56k</td>\n",
       "      <td>4/14/2016 16:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143684</th>\n",
       "      <td>11328102</td>\n",
       "      <td>New JSON parser for Go: up to 9x faster than `...</td>\n",
       "      <td>https://github.com/buger/jsonparser</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>LeonidBugaev</td>\n",
       "      <td>3/21/2016 14:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33633</th>\n",
       "      <td>12274980</td>\n",
       "      <td>Ask HN: Is anyone using json schema?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>luney</td>\n",
       "      <td>8/12/2016 12:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183140</th>\n",
       "      <td>11012770</td>\n",
       "      <td>Picky.json  Dump JSON (raw or URL). Click Some...</td>\n",
       "      <td>http://pickyjson.com</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>CorySimmons</td>\n",
       "      <td>2/1/2016 16:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177640</th>\n",
       "      <td>11058070</td>\n",
       "      <td>Show HN: Electron-json-storage  Easily write a...</td>\n",
       "      <td>https://github.com/jviotti/electron-json-storage</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>jviotti</td>\n",
       "      <td>2/8/2016 13:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "123721  11497826                              Hjson, the Human JSON   \n",
       "143684  11328102  New JSON parser for Go: up to 9x faster than `...   \n",
       "33633   12274980               Ask HN: Is anyone using json schema?   \n",
       "183140  11012770  Picky.json  Dump JSON (raw or URL). Click Some...   \n",
       "177640  11058070  Show HN: Electron-json-storage  Easily write a...   \n",
       "\n",
       "                                                     url  num_points  \\\n",
       "123721                                 http://hjson.org/         257   \n",
       "143684               https://github.com/buger/jsonparser          20   \n",
       "33633                                                NaN          14   \n",
       "183140                              http://pickyjson.com          14   \n",
       "177640  https://github.com/jviotti/electron-json-storage          12   \n",
       "\n",
       "        num_comments        author       created_at  \n",
       "123721           214           56k  4/14/2016 16:06  \n",
       "143684            14  LeonidBugaev  3/21/2016 14:05  \n",
       "33633             17         luney  8/12/2016 12:17  \n",
       "183140             0   CorySimmons   2/1/2016 16:32  \n",
       "177640             0       jviotti   2/8/2016 13:57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show some nearest neighbor samples\n",
    "\n",
    "k = 5\n",
    "\n",
    "word = input('Enter search word: ')\n",
    "nearest_neighbours = {}\n",
    "\n",
    "# by computing the cosine similarity between the search word's vector and all other word vectors, we find and display the nearest neighbors to this word based on their vector representations in the reduced-dimensional space\n",
    "for x in cx:\n",
    "    if x == word:\n",
    "        dd = np.dot(U, U[x2i[x]])\n",
    "    \n",
    "        for i in np.argpartition(-1 * dd, k + 1)[:k + 1]:\n",
    "            if i2x[i] == x: \n",
    "                continue\n",
    "                        \n",
    "            nearest_neighbours[i2x[i]] = dd[i]\n",
    "\n",
    "# For each of the nearest neighbor words, we retrieve and display articles from the original dataset that contain the neighbor word, sorted by a scoring metric (num_points).\n",
    "for nn in nearest_neighbours:\n",
    "    print(nn)\n",
    "    similar_articles = df[df['title'].str.contains(nn)]\n",
    "    display(similar_articles.sort_values(by='num_points',ascending=False)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
